{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Edge-AI와 3D Depth Camera\n",
    "\n",
    "3D Depth Camera는 공간의 깊이 정보를 캡처하여 3차원 데이터로 변환하는 장치입니다. 이러한 카메라는 다양한 응용 분야에서 사용되며, 컴퓨터 비전, 로봇 공학, 증강현실(AR), 가상현실(VR), 의료 이미지 처리 등에서 중요합니다. 본 강의에서는 3D Depth Camera의 원리, 기술, 응용 사례, 그리고 DeepStream을 활용할 수 있는 방법에 대해 설명합니다.\n",
    "\n",
    "## 03-2. 3D Depth Camera\n",
    "\n",
    "### 3D Depth Camera의 정의\n",
    "3D Depth Camera는 객체나 장면의 깊이 정보를 캡처할 수 있는 장치로, 카메라가 각 픽셀의 거리 값을 캡처하여 3차원 공간에서 물체를 인식하거나 측정할 수 있도록 합니다.\n",
    "\n",
    "### 3D Depth Camera의 원리\n",
    "1. **스테레오 비전 (Stereo Vision)**:\n",
    "    * 두 개의 카메라로 물체를 촬영한 이미지를 비교하여 깊이를 계산합니다.\n",
    "    * 사람의 시각 시스템과 유사한 방식입니다.\n",
    "\n",
    "2. **구조광 (Structured Light)**:\n",
    "    * 특정 패턴의 빛을 물체에 투사하고, 왜곡된 패턴을 분석하여 깊이를 측정합니다.\n",
    "    * 대표적인 예: Microsoft Kinect\n",
    "\n",
    "3. **비행시간 (Time of Flight, ToF)**:\n",
    "    * 빛이 물체에 반사되어 돌아오는 시간을 측정하여 깊이를 계산합니다.\n",
    "    * 정확하고 빠른 깊이 측정이 가능합니다.\n",
    "\n",
    "4. **LiDAR (Light Detection and Ranging)**:\n",
    "    * 레이저를 사용해 주변 환경을 스캔하여 깊이를 측정합니다.\n",
    "    * 자율주행차에 주로 사용됩니다.\n",
    "\n",
    "### 응용 분야\n",
    "1. **산업 및 제조**:\n",
    "    * 로봇 비전: 로봇의 정확한 동작과 위치 결정을 지원.\n",
    "    * 품질 검사: 제품의 결함 및 크기 측정.\n",
    "2. **의료**:\n",
    "    * 3D 스캔: 인체를 스캔하여 맞춤형 의료 장비 제작.\n",
    "    * 수술 보조: 정확한 수술 계획을 위한 3D 모델 생성.\n",
    "3. **엔터테인먼트**:\n",
    "    * 증강현실/가상현실(AR/VR): 몰입형 환경 구축.\n",
    "    * 게임: 사용자 동작을 추적하여 인터랙션 제공.\n",
    "4. **도매(Retail)**:\n",
    "    * 고객 행동 분석: 매장 내 고객의 동선을 추적하고 행동을 분석.\n",
    "    * 재고 관리: 제품 크기 및 위치를 자동으로 스캔하여 재고를 효율적으로 관리.\n",
    "    * 무인 매장: 3D 데이터를 활용해 고객과 제품의 상호작용을 자동화."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03-3. OAK-D 모듈\n",
    "- **OAK-D 모듈 소개**: OAK-D(OpenCV AI Kit Depth)는 AI 및 컴퓨터 비전 기능을 갖춘 카메라 모듈로, 실시간으로 깊이 정보를 제공하며 다양한 응용 분야에 적합합니다.\n",
    "\n",
    "- **주요 특징**:\n",
    "  1. **내장형 AI**: Myriad X VPU를 탑재하여 온보드 AI 처리 가능.\n",
    "  2. **스테레오 비전**: 두 개의 모노 카메라로 깊이 정보 계산.\n",
    "  3. **컬러 카메라**: 고해상도 컬러 카메라로 세부 정보를 캡처.\n",
    "  4. **플러그 앤 플레이**: USB를 통해 쉽게 연결 및 사용 가능.\n",
    "  5. **다양한 SDK 지원**: DepthAI 및 OpenCV와 같은 SDK 지원.\n",
    "\n",
    "- **응용 사례**:\n",
    "  - 로봇 내비게이션\n",
    "  - 객체 추적 및 감지\n",
    "  - 증강 현실 및 가상 현실 애플리케이션\n",
    "\n",
    "### OAK-D PRO의 자체 기능과 기술\n",
    "- **IMU 센서**: 내장된 IMU 센서로 자세와 움직임을 추적할 수 있다.\n",
    "- **AI 프로세싱**: 내장된 AI 칩으로 머신러닝 모델을 로컬에서 실행 가능.\n",
    "- **다중 카메라**: 컬러 카메라와 두 개의 모노 카메라를 사용하여 스테레오 비전 지원.\n",
    "- **ROS 지원**: 로봇 운영 체제(ROS)와의 통합 용이.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 예제 실습\n",
    "\n",
    "## Jetson Orin Nano에서 Camera module setting (Connection)\n",
    "\n",
    "### 준비물\n",
    "- Jetson Orin Nano\n",
    "- OAK-D PRO Camera\n",
    "- USB-C 케이블\n",
    "\n",
    "### 필수 라이브러리 설치\n",
    "라이브러리 설치\n",
    "```bash\n",
    "# 설치되어있는 OpenCV 삭제\n",
    "$ pip uninstall opencv-python\n",
    "\n",
    "# 저장소 추가\n",
    "$ sudo add-apt-repository universe\n",
    "$ sudo apt update\n",
    "\n",
    "# 필수 라이브러리 설치\n",
    "$ sudo apt install -y build-essential cmake git pkg-config libgtk-3-dev libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libxvidcore-dev libx264-dev libjpeg-dev libpng-dev libtiff-dev gfortran openexr libatlas-base-dev python3-dev python3-numpy libtbb2 libtbb-dev libdc1394-dev\n",
    "\n",
    "# OpenCV 설치\n",
    "pip install opencv-python\n",
    "```\n",
    "\n",
    "OAK-D 관련 드라이버 설치\n",
    "```bash\n",
    "$ wget -qO- https://docs.luxonis.com/install_dependencies.sh | bash\n",
    "$ pip install depthai --upgrade\n",
    "```\n",
    "* 드라이버 설치 이후 반드시 OAK-D 모듈 연결 USB를 뺐다가 다시 꽂기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline started\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import depthai as dai\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Create ColorCamera node\n",
    "cam = pipeline.create(dai.node.ColorCamera)\n",
    "cam.setBoardSocket(dai.CameraBoardSocket.CAM_A)  # CAM_A로 수정\n",
    "cam.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "cam.setVideoSize(1920, 1080)\n",
    "\n",
    "# Create XLinkOut node\n",
    "xout = pipeline.create(dai.node.XLinkOut)\n",
    "xout.setStreamName(\"video\")\n",
    "\n",
    "# Connect camera to output\n",
    "cam.video.link(xout.input)\n",
    "\n",
    "# Start the pipeline\n",
    "with dai.Device(pipeline) as device:\n",
    "    print(\"Pipeline started\")\n",
    "    video = device.getOutputQueue(name=\"video\", maxSize=4, blocking=False)\n",
    "    \n",
    "    while True:\n",
    "        # Get frame\n",
    "        frame = video.get().getCvFrame()\n",
    "        \n",
    "        # Show frame\n",
    "        cv2.imshow(\"OAK-D Video Feed\", frame)\n",
    "        \n",
    "        # Exit on 'q' key\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Clear previous output and display frame\u001b[39;00m\n\u001b[1;32m     48\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 49\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m ax\u001b[38;5;241m.\u001b[39mimshow(frame_rgb)\n\u001b[1;32m     51\u001b[0m ax\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py:1475\u001b[0m, in \u001b[0;36m_AxesBase.clear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclear\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Clear the Axes.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcla\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py:1195\u001b[0m, in \u001b[0;36m_AxesBase.cla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m xaxis_visible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mget_visible()\n\u001b[1;32m   1193\u001b[0m yaxis_visible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mget_visible()\n\u001b[0;32m-> 1195\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, spine \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspines\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py:818\u001b[0m, in \u001b[0;36mAxis.clear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_major_tick_kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgridOn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    813\u001b[0m         mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.grid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    814\u001b[0m         mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.grid.which\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmajor\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_minor_tick_kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgridOn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    816\u001b[0m         mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.grid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    817\u001b[0m         mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.grid.which\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminor\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m--> 818\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py:846\u001b[0m, in \u001b[0;36mAxis.reset_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 846\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_clip_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py:936\u001b[0m, in \u001b[0;36mAxis.set_clip_path\u001b[0;34m(self, clippath, transform)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_clip_path\u001b[39m(\u001b[38;5;28mself\u001b[39m, clippath, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mset_clip_path(clippath, transform)\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajorTicks \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminorTicks\u001b[49m:\n\u001b[1;32m    937\u001b[0m         child\u001b[38;5;241m.\u001b[39mset_clip_path(clippath, transform)\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py:597\u001b[0m, in \u001b[0;36m_LazyTickList.__get__\u001b[0;34m(self, instance, cls)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    596\u001b[0m     instance\u001b[38;5;241m.\u001b[39mminorTicks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 597\u001b[0m     tick \u001b[38;5;241m=\u001b[39m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tick\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m     instance\u001b[38;5;241m.\u001b[39mminorTicks\u001b[38;5;241m.\u001b[39mappend(tick)\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mminorTicks\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py:2057\u001b[0m, in \u001b[0;36mXAxis._get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     tick_kw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_minor_tick_kw\n\u001b[0;32m-> 2057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mXTick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmajor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtick_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py:415\u001b[0m, in \u001b[0;36mXTick.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# x in data coords, y in axes coords\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py:150\u001b[0m, in \u001b[0;36mTick.__init__\u001b[0;34m(self, axes, loc, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kw)\u001b[0m\n\u001b[1;32m    147\u001b[0m     grid_alpha \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrid.alpha\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    148\u001b[0m grid_kw \u001b[38;5;241m=\u001b[39m {k[\u001b[38;5;241m5\u001b[39m:]: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kw\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtick1line \u001b[38;5;241m=\u001b[39m \u001b[43mmlines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLine2D\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinestyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzorder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzorder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisible\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtick1On\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmarkeredgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkersize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkeredgewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtick2line \u001b[38;5;241m=\u001b[39m mlines\u001b[38;5;241m.\u001b[39mLine2D(\n\u001b[1;32m    156\u001b[0m     [], [],\n\u001b[1;32m    157\u001b[0m     color\u001b[38;5;241m=\u001b[39mcolor, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, zorder\u001b[38;5;241m=\u001b[39mzorder, visible\u001b[38;5;241m=\u001b[39mtick2On,\n\u001b[1;32m    158\u001b[0m     markeredgecolor\u001b[38;5;241m=\u001b[39mcolor, markersize\u001b[38;5;241m=\u001b[39msize, markeredgewidth\u001b[38;5;241m=\u001b[39mwidth,\n\u001b[1;32m    159\u001b[0m )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgridline \u001b[38;5;241m=\u001b[39m mlines\u001b[38;5;241m.\u001b[39mLine2D(\n\u001b[1;32m    161\u001b[0m     [], [],\n\u001b[1;32m    162\u001b[0m     color\u001b[38;5;241m=\u001b[39mgrid_color, alpha\u001b[38;5;241m=\u001b[39mgrid_alpha, visible\u001b[38;5;241m=\u001b[39mgridOn,\n\u001b[1;32m    163\u001b[0m     linestyle\u001b[38;5;241m=\u001b[39mgrid_linestyle, linewidth\u001b[38;5;241m=\u001b[39mgrid_linewidth, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgrid_kw,\n\u001b[1;32m    165\u001b[0m )\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/lines.py:310\u001b[0m, in \u001b[0;36mLine2D.__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xdata, ydata,\n\u001b[1;32m    277\u001b[0m              linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# all Nones default to rc\u001b[39;00m\n\u001b[1;32m    278\u001b[0m              linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    296\u001b[0m              ):\n\u001b[1;32m    297\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    Create a `.Line2D` instance with *x* and *y* data in sequences of\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m    *xdata*, *ydata*.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# Convert sequences to NumPy arrays.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39miterable(xdata):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Create ColorCamera node\n",
    "cam = pipeline.create(dai.node.ColorCamera)\n",
    "cam.setBoardSocket(dai.CameraBoardSocket.CAM_A)\n",
    "cam.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "cam.setVideoSize(1920, 1080)\n",
    "\n",
    "# Create XLinkOut node\n",
    "xout = pipeline.create(dai.node.XLinkOut)\n",
    "xout.setStreamName(\"video\")\n",
    "\n",
    "# Connect camera to output\n",
    "cam.video.link(xout.input)\n",
    "\n",
    "# Start the pipeline\n",
    "with dai.Device(pipeline) as device:\n",
    "    print(\"Pipeline started\")\n",
    "    video = device.getOutputQueue(name=\"video\", maxSize=4, blocking=False)\n",
    "    \n",
    "    while True:\n",
    "        # Get frame\n",
    "        frame = video.get().getCvFrame()\n",
    "        \n",
    "        # Convert to RGB for Matplotlib\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display frame in Jupyter Notebook\n",
    "        clear_output(wait=True)\n",
    "        plt.imshow(frame_rgb)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OAK-D와 DeepStream을 결합한 ObjectDetection\n",
    "\n",
    "### 준비물\n",
    "* Jetson\n",
    "* DeepStream 설치\n",
    "* OAK-D 카메라 모듈\n",
    "\n",
    "### 실행 준비\n",
    "폴더 만들기\n",
    "```bash\n",
    "$ mkdir jetson-oakd\n",
    "```\n",
    "\n",
    "DeepStream 파이프라인 파일 작성(deepstream-oakd.c)\n",
    "```c\n",
    "#include <gst/gst.h>\n",
    "#include <glib.h>\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime_api.h>\n",
    "#include \"gstnvdsmeta.h\"\n",
    "#include \"nvds_yml_parser.h\"\n",
    "#include <depthai/depthai.hpp>\n",
    "\n",
    "#define MAX_DISPLAY_LEN 64\n",
    "\n",
    "gint frame_number = 0;\n",
    "gchar pgie_classes_str[4][32] = {\"Vehicle\", \"TwoWheeler\", \"Person\", \"Roadsign\"};\n",
    "\n",
    "typedef struct\n",
    "{\n",
    "    dai::Pipeline pipeline;\n",
    "    std::shared_ptr<dai::Device> device;\n",
    "    std::shared_ptr<dai::DataOutputQueue> rgbQueue;\n",
    "} OAKDSource;\n",
    "\n",
    "// OAK-D 초기화\n",
    "OAKDSource init_oakd()\n",
    "{\n",
    "    OAKDSource oakdSource;\n",
    "    oakdSource.pipeline = dai::Pipeline();\n",
    "\n",
    "    // ColorCamera 노드 생성\n",
    "    auto camRgb = oakdSource.pipeline.create<dai::node::ColorCamera>();\n",
    "    camRgb->setResolution(dai::ColorCameraProperties::SensorResolution::THE_1080_P);\n",
    "    camRgb->setInterleaved(false);\n",
    "    camRgb->setColorOrder(dai::ColorCameraProperties::ColorOrder::BGR);\n",
    "\n",
    "    // XLinkOut 노드 생성\n",
    "    auto xoutRgb = oakdSource.pipeline.create<dai::node::XLinkOut>();\n",
    "    xoutRgb->setStreamName(\"rgb\");\n",
    "    camRgb->video.link(xoutRgb->input);\n",
    "\n",
    "    // OAK-D 장치 연결\n",
    "    oakdSource.device = std::make_shared<dai::Device>(oakdSource.pipeline);\n",
    "\n",
    "    // RGB 출력 큐 생성\n",
    "    oakdSource.rgbQueue = oakdSource.device->getOutputQueue(\"rgb\", 8, false);\n",
    "\n",
    "    return oakdSource;\n",
    "}\n",
    "\n",
    "// appsrc 데이터 푸시 콜백\n",
    "GstFlowReturn push_frame_to_gstreamer(GstElement *appsrc, guint size, gpointer user_data)\n",
    "{\n",
    "    OAKDSource *oakdSource = (OAKDSource *)user_data;\n",
    "    auto imgFrame = oakdSource->rgbQueue->get<dai::ImgFrame>();\n",
    "    if (!imgFrame)\n",
    "    {\n",
    "        return GST_FLOW_EOS;\n",
    "    }\n",
    "\n",
    "    // RGB 데이터를 GStreamer 버퍼로 변환\n",
    "    GstBuffer *buffer = gst_buffer_new_wrapped(imgFrame->getData().data(), imgFrame->getData().size());\n",
    "\n",
    "    // 버퍼 푸시\n",
    "    GstFlowReturn ret;\n",
    "    g_signal_emit_by_name(appsrc, \"push-buffer\", buffer, &ret);\n",
    "    gst_buffer_unref(buffer);\n",
    "\n",
    "    return ret;\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{\n",
    "    GstElement *pipeline, *appsrc, *h264parser, *decoder, *sink;\n",
    "    GstBus *bus;\n",
    "    GMainLoop *loop;\n",
    "\n",
    "    // GStreamer 초기화\n",
    "    gst_init(&argc, &argv);\n",
    "\n",
    "    // OAK-D 초기화\n",
    "    OAKDSource oakdSource = init_oakd();\n",
    "\n",
    "    // GStreamer 파이프라인 생성\n",
    "    pipeline = gst_pipeline_new(\"oakd-pipeline\");\n",
    "\n",
    "    // appsrc 생성\n",
    "    appsrc = gst_element_factory_make(\"appsrc\", \"oakd-appsrc\");\n",
    "    g_object_set(G_OBJECT(appsrc), \"caps\", gst_caps_from_string(\"video/x-raw,format=BGR,width=1920,height=1080,framerate=30/1\"), NULL);\n",
    "    g_signal_connect(appsrc, \"need-data\", G_CALLBACK(push_frame_to_gstreamer), &oakdSource);\n",
    "\n",
    "    // GStreamer 요소 생성\n",
    "    h264parser = gst_element_factory_make(\"h264parse\", \"h264-parser\");\n",
    "    decoder = gst_element_factory_make(\"nvv4l2decoder\", \"nvv4l2-decoder\");\n",
    "    sink = gst_element_factory_make(\"nveglglessink\", \"video-output\");\n",
    "\n",
    "    if (!pipeline || !appsrc || !h264parser || !decoder || !sink)\n",
    "    {\n",
    "        g_printerr(\"Failed to create GStreamer elements.\\n\");\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    // 파이프라인에 요소 추가\n",
    "    gst_bin_add_many(GST_BIN(pipeline), appsrc, h264parser, decoder, sink, NULL);\n",
    "\n",
    "    // 요소 연결\n",
    "    if (!gst_element_link_many(appsrc, h264parser, decoder, sink, NULL))\n",
    "    {\n",
    "        g_printerr(\"Failed to link elements.\\n\");\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    // 파이프라인 실행\n",
    "    gst_element_set_state(pipeline, GST_STATE_PLAYING);\n",
    "\n",
    "    // 이벤트 루프 시작\n",
    "    loop = g_main_loop_new(NULL, FALSE);\n",
    "    g_main_loop_run(loop);\n",
    "\n",
    "    // 종료 처리\n",
    "    gst_element_set_state(pipeline, GST_STATE_NULL);\n",
    "    gst_object_unref(pipeline);\n",
    "    g_main_loop_unref(loop);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
