{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1d63e1",
   "metadata": {},
   "source": [
    "# DeepStream 활용하여 YOLO 모델 실행하기\n",
    "\n",
    "이 강의에서는 YOLOv11 모델을 TensorRT 엔진 파일(`yolo11n.engine`)로 실행하여 DeepStream 애플리케이션에 통합하는 과정을 다룹니다. DeepStream은 NVIDIA의 고성능 비디오 분석 SDK로, TensorRT와 함께 동작하여 효율적인 딥러닝 추론을 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265dab95",
   "metadata": {},
   "source": [
    "## **1. DeepStream과 TensorRT 개요**\n",
    "- **DeepStream**: NVIDIA의 스트림 기반 비디오 분석 SDK로, TensorRT 엔진 파일을 활용하여 실시간 추론을 지원합니다.\n",
    "- **TensorRT 엔진 파일**: ONNX 모델에서 변환된 최적화된 파일로, DeepStream에서 추론에 사용됩니다.\n",
    "\n",
    "DeepStream 애플리케이션의 기본 구성:\n",
    "1. 소스 입력 (RTSP, 파일 등)\n",
    "2. 추론 수행 (YOLOv11 엔진 활용)\n",
    "3. 결과 시각화 또는 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c437d06",
   "metadata": {},
   "source": [
    "## **2. 환경 설정**\n",
    "DeepStream 애플리케이션을 실행하기 전, 필요한 설정을 진행합니다.\n",
    "\n",
    "### **필요 파일**\n",
    "1. TensorRT 엔진 파일: `yolo11n.engine`\n",
    "2. DeepStream 구성 파일: `config_infer_primary_yolo11n.txt`\n",
    "\n",
    "구성 파일은 모델 경로 및 추론 파라미터를 정의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96404769",
   "metadata": {},
   "source": [
    "### **구성 파일 예제**\n",
    "아래는 `config_infer_primary_yolo11n.txt`의 예제입니다:\n",
    "\n",
    "```txt\n",
    "[property]\n",
    "gpu-id=0\n",
    "model-engine-file=yolo11n.engine\n",
    "labelfile-path=labels.txt\n",
    "batch-size=1\n",
    "network-mode=0\n",
    "num-detected-classes=80\n",
    "interval=0\n",
    "gie-unique-id=1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b53e4",
   "metadata": {},
   "source": [
    "## **3. DeepStream 애플리케이션 코드**\n",
    "이제 Python을 사용하여 DeepStream 애플리케이션을 실행하는 코드를 작성합니다. 이 코드는 TensorRT 엔진 파일을 로드하고, 비디오 스트림에서 추론을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505bcd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import gi\n",
    "import sys\n",
    "\n",
    "# GStreamer와 DeepStream 플러그인을 임포트합니다.\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import Gst\n",
    "\n",
    "# GStreamer 초기화\n",
    "Gst.init(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepStream 파이프라인 생성\n",
    "pipeline = Gst.parse_launch(\n",
    "    \"filesrc location=sample_video.mp4 ! decodebin ! nvstreammux name=mux batch-size=1 ! \"\n",
    "    \"nvinfer config-file-path=config_infer_primary_yolo11n.txt ! nvtracker ! \"\n",
    "    \"nvmultistreamtiler ! nvvideoconvert ! nvdsosd ! nveglglessink\"\n",
    ")\n",
    "\n",
    "# 파이프라인 확인\n",
    "if not pipeline:\n",
    "    print(\"파이프라인 생성 실패\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5049931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 실행\n",
    "def run_pipeline():\n",
    "    try:\n",
    "        pipeline.set_state(Gst.State.PLAYING)\n",
    "        print(\"DeepStream 파이프라인 실행 중...\")\n",
    "\n",
    "        # GStreamer 버스에서 메시지 수신\n",
    "        bus = pipeline.get_bus()\n",
    "        while True:\n",
    "            msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)\n",
    "            if msg:\n",
    "                t = msg.type\n",
    "                if t == Gst.MessageType.ERROR:\n",
    "                    err, debug = msg.parse_error()\n",
    "                    print(f\"에러: {err}, 디버그 정보: {debug}\")\n",
    "                    break\n",
    "                elif t == Gst.MessageType.EOS:\n",
    "                    print(\"End-Of-Stream 도달\")\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"파이프라인 실행 중 오류 발생: {e}\")\n",
    "    finally:\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "\n",
    "# 실행\n",
    "run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b4a25c",
   "metadata": {},
   "source": [
    "## **4. 실행 방법**\n",
    "1. 위 코드와 `config_infer_primary_yolo11n.txt` 파일을 동일한 디렉토리에 저장합니다.\n",
    "2. `yolo11n.engine` 파일도 같은 위치에 배치합니다.\n",
    "3. Python 파일을 실행하여 DeepStream 파이프라인을 실행합니다.\n",
    "\n",
    "```bash\n",
    "python3 deepstream_yolo11n.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104c61d",
   "metadata": {},
   "source": [
    "## **5. 요약 및 정리**\n",
    "- TensorRT 엔진 파일과 DeepStream 구성 파일을 활용하여 실시간 추론을 수행하는 방법을 학습했습니다.\n",
    "- YOLOv11 모델을 사용하여 비디오 스트림에서 객체 탐지를 수행했습니다.\n",
    "추가적으로 원하는 모델로 확장하거나 커스터마이징이 가능합니다."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
