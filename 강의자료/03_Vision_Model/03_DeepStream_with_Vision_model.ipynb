{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. DeepStream with Vision model\n",
    "\n",
    "이 강의에서는 ONNX 파일을 TensorRT 엔진 파일로 변환하여 DeepStream 애플리케이션에 배포하는 과정을 안내합니다. TensorRT는 딥러닝 모델의 추론을 최적화하여 고성능, 저지연 결과를 제공합니다.\n",
    "\n",
    "## 03-2. TensorRT와 ONNX 소개\n",
    "- **TensorRT**: NVIDIA에서 개발한 고성능 딥러닝 추론 최적화 및 런타임 라이브러리.\n",
    "- **ONNX (Open Neural Network Exchange)**: 다양한 프레임워크 간 상호 운용성을 지원하는 딥러닝 모델 표현 형식.\n",
    "\n",
    "### TensorRT로 변화하는 이유는? ###\n",
    "- GPU 활용도를 극대화합니다.\n",
    "- 모델 추론 지연 시간을 줄입니다.\n",
    "- 추론을 위한 메모리 사용을 최적화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "\n",
    "# 실습\n",
    "\n",
    "## YOLOv8 모델로 engin파일 만들기\n",
    "\n",
    "### 하드웨어 및 소프트웨어 요구 사항\n",
    "- TensorRT를 지원하는 NVIDIA GPU.\n",
    "- TensorRT SDK 설치.\n",
    "- Python 환경 (Python 3.7 이상).\n",
    "- 학습된 모델의 ONNX 파일.\n",
    "- DeepStream 설치(테스트 용도, 선택 사항).\n",
    "\n",
    "### **라이브러리 및 의존성**\n",
    "Python 환경에서 다음 명령어로 필요한 라이브러리를 설치합니다:\n",
    "```bash\n",
    "pip install onnx onnxruntime tensorrt pycuda\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT 빌더 스크립트 준비\n",
    "\n",
    "TensorRT는 ONNX 모델을 엔진 파일로 변환하는 도구를 제공합니다. 아래는 Python 기반의 접근 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "# TensorRT 로거\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def build_engine(onnx_file_path, engine_file_path):\n",
    "    # 빌더, 네트워크, 설정 생성\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "        # 빌더 구성\n",
    "        builder.max_batch_size = 1\n",
    "        config = builder.create_builder_config()\n",
    "        config.max_workspace_size = 1 << 30  # 1 GB\n",
    "\n",
    "        # ONNX 파일 파싱\n",
    "        with open(onnx_file_path, 'rb') as model:\n",
    "            if not parser.parse(model.read()):\n",
    "                print(\"ONNX 파일 파싱에 실패했습니다.\")\n",
    "                for error in range(parser.num_errors):\n",
    "                    print(parser.get_error(error))\n",
    "                return None\n",
    "\n",
    "        # 엔진 빌드 및 직렬화\n",
    "        engine = builder.build_engine(network, config)\n",
    "        with open(engine_file_path, \"wb\") as f:\n",
    "            f.write(engine.serialize())\n",
    "        print(f\"엔진 파일이 {engine_file_path}에 저장되었습니다.\")\n",
    "\n",
    "# 예제 사용법\n",
    "build_engine(\"model.onnx\", \"model.engine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 엔진 파일 테스트\n",
    "\n",
    "`.engine` 파일이 생성되면, 올바르게 동작하는지 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "\n",
    "# TensorRT 엔진 로드\n",
    "def load_engine(engine_file_path):\n",
    "    with open(engine_file_path, \"rb\") as f:\n",
    "        runtime = trt.Runtime(TRT_LOGGER)\n",
    "        return runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "engine = load_engine(\"model.engine\")\n",
    "print(\"엔진이 성공적으로 로드되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepStream에서 활용\n",
    "1. **엔진 파일 배치**: `.engine` 파일을 원하는 디렉터리로 이동합니다.\n",
    "2. **DeepStream 구성 업데이트**: `config_infer_primary.txt` 파일을 수정하여 새 엔진 파일을 사용하도록 설정합니다.\n",
    "\n",
    "예제:\n",
    "```txt\n",
    "[property]\n",
    "model-engine-file=model.engine\n",
    "labelfile-path=labels.txt\n",
    "batch-size=1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
