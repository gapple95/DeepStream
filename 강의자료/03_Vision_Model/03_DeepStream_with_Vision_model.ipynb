{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. DeepStream with Vision model\n",
    "\n",
    "ì´ ê°•ì˜ì—ì„œëŠ” ONNX íŒŒì¼ì„ TensorRT ì—”ì§„ íŒŒì¼ë¡œ ë³€í™˜í•˜ì—¬ DeepStream ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë°°í¬í•˜ëŠ” ê³¼ì •ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. TensorRTëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì¶”ë¡ ì„ ìµœì í™”í•˜ì—¬ ê³ ì„±ëŠ¥, ì €ì§€ì—° ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "## 03-2. DeepStreamê³¼ TensorRT ê°œìš”\n",
    "- **DeepStream**: NVIDIAì˜ ìŠ¤íŠ¸ë¦¼ ê¸°ë°˜ ë¹„ë””ì˜¤ ë¶„ì„ SDKë¡œ, TensorRT ì—”ì§„ íŒŒì¼ì„ í™œìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì¶”ë¡ ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "- **TensorRT ì—”ì§„ íŒŒì¼**: ONNX ëª¨ë¸ì—ì„œ ë³€í™˜ëœ ìµœì í™”ëœ íŒŒì¼ë¡œ, DeepStreamì—ì„œ ì¶”ë¡ ì— ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "### DeepStream ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê¸°ë³¸ êµ¬ì„±:\n",
    "1. ì†ŒìŠ¤ ì…ë ¥ (RTSP, íŒŒì¼ ë“±)\n",
    "2. ì¶”ë¡  ìˆ˜í–‰ (TensorRTìš© ëª¨ë¸ í™œìš©)\n",
    "    * ONNX ëª¨ë¸ì„ TensorRìš© engineíŒŒì¼ë¡œ ë³€í™˜í•´ì„œ ì‚¬ìš©\n",
    "3. ê²°ê³¼ ì‹œê°í™” ë˜ëŠ” ì €ì¥\n",
    "\n",
    "## 03-3. TensorRTì™€ ONNX\n",
    "- **TensorRT**: NVIDIAì—ì„œ ê°œë°œí•œ ê³ ì„±ëŠ¥ ë”¥ëŸ¬ë‹ ì¶”ë¡  ìµœì í™” ë° ëŸ°íƒ€ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬.\n",
    "- **ONNX (Open Neural Network Exchange)**: ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ ê°„ ìƒí˜¸ ìš´ìš©ì„±ì„ ì§€ì›í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ í‘œí˜„ í˜•ì‹.\n",
    "\n",
    "### TensorRTë¡œ ë³€í™”í•˜ëŠ” ì´ìœ ëŠ”?\n",
    "- DeepStreamì—ì„œëŠ” TensorRT ëª¨ë¸ë§Œ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "- GPU í™œìš©ë„ë¥¼ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.\n",
    "- ëª¨ë¸ ì¶”ë¡  ì§€ì—° ì‹œê°„ì„ ì¤„ì…ë‹ˆë‹¤.\n",
    "- ì¶”ë¡ ì„ ìœ„í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ìµœì í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "\n",
    "# ì‹¤ìŠµ\n",
    "\n",
    "## YOLOv11 ëª¨ë¸ë¡œ enginíŒŒì¼ ë§Œë“¤ê¸°\n",
    "\n",
    "### í•˜ë“œì›¨ì–´ ë° ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ ì‚¬í•­\n",
    "- TensorRTë¥¼ ì§€ì›í•˜ëŠ” NVIDIA GPU.\n",
    "- TensorRT SDK ì„¤\n",
    "- Python í™˜ê²½ (ë³¸ ì‹¤ìŠµì€ Python 3.10)\n",
    "- DeepStream ì„¤ì¹˜(í…ŒìŠ¤íŠ¸ ìš©ë„, ì„ íƒ ì‚¬í•­)\n",
    "\n",
    "### ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì˜ì¡´ì„±\n",
    "Python í™˜ê²½ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤:\n",
    "```bash\n",
    "$ sudo pip3 install onnx onnxruntime tensorrt pycuda\n",
    "```\n",
    "\n",
    "### YOLOv11 onnx ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n",
    "YOLO ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° numpy 1.23 ë²„ì „ ì„¤ì¹˜\n",
    "\n",
    "```bash\n",
    "$ sudo pip3 install ultralytics\n",
    "$ sudo pip3 install numpy==1.23\n",
    "```\n",
    "\n",
    "#### 1. Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì´ìš©í•œ YOLOv11.onnx ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.65 ğŸš€ Python-3.10.12 torch-2.5.1 CPU (ARMv8 Processor rev 1 (v8l))\n",
      "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.47...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 4.3s, saved as 'yolo11n.onnx' (10.2 MB)\n",
      "\n",
      "Export complete (7.0s)\n",
      "Results saved to \u001b[1m/home/paymentinapp/Desktop/lecture/DeepStream/ê°•ì˜ìë£Œ/03_Vision_Model\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolo11n.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "WARNING âš ï¸ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Export the model to ONNX format\n",
    "model.export(format=\"onnx\")  # creates 'yolo11n.onnx'\n",
    "\n",
    "# Load the exported ONNX model\n",
    "onnx_model = YOLO(\"yolo11n.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. CLIë¥¼ ì´ìš©í•œ YOLOv11.onnx ë‹¤ìš´ë¡œë“œ\n",
    "```bash\n",
    "$ yolo export model=yolo11n.pt format=onnx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT ë¹Œë” ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„\n",
    "\n",
    "TensorRTëŠ” ONNX ëª¨ë¸ì„ ì—”ì§„ íŒŒì¼ë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì•„ë˜ëŠ” Python ê¸°ë°˜ì˜ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì—”ì§„ íŒŒì¼ì´ yolo11n.engineì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "# TensorRT ë¡œê±°\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def build_engine(onnx_file_path, engine_file_path):\n",
    "    # ë¹Œë”, ë„¤íŠ¸ì›Œí¬, ì„¤ì • ìƒì„±\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        \n",
    "        # ë¹Œë” êµ¬ì„±\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1GB ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "\n",
    "        # ONNX íŒŒì¼ íŒŒì‹±\n",
    "        with open(onnx_file_path, 'rb') as model:\n",
    "            if not parser.parse(model.read()):\n",
    "                print(\"ONNX íŒŒì¼ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "                for error in range(parser.num_errors):\n",
    "                    print(parser.get_error(error))\n",
    "                return None\n",
    "\n",
    "        # ë„¤íŠ¸ì›Œí¬ë¥¼ ì§ë ¬í™”í•˜ì—¬ ì—”ì§„ ìƒì„±\n",
    "        serialized_engine = builder.build_serialized_network(network, config)\n",
    "        if serialized_engine is None:\n",
    "            print(\"ì—”ì§„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "\n",
    "        # ì—”ì§„ íŒŒì¼ ì €ì¥\n",
    "        with open(engine_file_path, \"wb\") as f:\n",
    "            f.write(serialized_engine)\n",
    "        print(f\"ì—”ì§„ íŒŒì¼ì´ {engine_file_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì˜ˆì œ ì‚¬ìš©ë²•\n",
    "build_engine(\"yolo11n.onnx\", \"yolo11n.engine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì—”ì§„ íŒŒì¼ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "`.engine` íŒŒì¼ì´ ìƒì„±ë˜ë©´, ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì—”ì§„ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "\n",
    "# TensorRT ì—”ì§„ ë¡œë“œ\n",
    "def load_engine(engine_file_path):\n",
    "    with open(engine_file_path, \"rb\") as f:\n",
    "        runtime = trt.Runtime(TRT_LOGGER)\n",
    "        return runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "engine = load_engine(\"yolo11n.engine\")\n",
    "print(\"ì—”ì§„ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepStreamì—ì„œ í™œìš©\n",
    "1. **ì—”ì§„ íŒŒì¼ ë°°ì¹˜**: `.engine` íŒŒì¼ì„ ì›í•˜ëŠ” ë””ë ‰í„°ë¦¬ë¡œ ì´ë™í•©ë‹ˆë‹¤.\n",
    "2. **DeepStream êµ¬ì„± ì—…ë°ì´íŠ¸**: `config_infer_primary.txt` íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ ìƒˆ ì—”ì§„ íŒŒì¼ì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "### **êµ¬ì„± íŒŒì¼ ì˜ˆì œ**\n",
    "ì•„ë˜ëŠ” `config_infer_primary_yolo11n.txt`ì˜ ì˜ˆì œì…ë‹ˆë‹¤:\n",
    "\n",
    "```txt\n",
    "[property]\n",
    "gpu-id=0\n",
    "model-engine-file=yolo11n.engine\n",
    "labelfile-path=labels.txt\n",
    "batch-size=1\n",
    "network-mode=0\n",
    "num-detected-classes=80\n",
    "interval=0\n",
    "gie-unique-id=1\n",
    "```\n",
    "\n",
    "ì•„ë˜ëŠ” config_infer_primary_yolo11n.txtë¥¼ ë§Œë“œëŠ” ì½”ë“œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_infer_primary_yolo11n.txt íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# config_infer_primary_yolo11n.txt íŒŒì¼ ìƒì„±\n",
    "config_content = \"\"\"[property]\n",
    "gpu-id=0\n",
    "model-engine-file=yolo11n.engine\n",
    "labelfile-path=labels.txt\n",
    "batch-size=1\n",
    "network-mode=0\n",
    "num-detected-classes=80\n",
    "interval=0\n",
    "gie-unique-id=1\n",
    "\"\"\"\n",
    "\n",
    "# íŒŒì¼ ì“°ê¸°\n",
    "with open(\"config_infer_primary_yolo11n.txt\", \"w\") as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"config_infer_primary_yolo11n.txt íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepStream ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ\n",
    "ì´ì œ Pythonì„ ì‚¬ìš©í•˜ì—¬ DeepStream ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. ì´ ì½”ë“œëŠ” TensorRT ì—”ì§„ íŒŒì¼ì„ ë¡œë“œí•˜ê³ , ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì—ì„œ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import gi\n",
    "import sys\n",
    "\n",
    "# GStreamerì™€ DeepStream í”ŒëŸ¬ê·¸ì¸ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import Gst\n",
    "\n",
    "# GStreamer ì´ˆê¸°í™”\n",
    "Gst.init(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "gst_parse_error: could not link nvvconv8 to mux, mux can't handle caps video/x-raw(memory:NVMM), format=(string)NV12 (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# DeepStream íŒŒì´í”„ë¼ì¸ ìƒì„± (nvv4l2camerasrc ì‚¬ìš©)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mGst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_launch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnvv4l2camerasrc device=/dev/video0 ! video/x-raw(memory:NVMM), width=1280, height=720, framerate=30/1 ! \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnvvidconv ! video/x-raw(memory:NVMM), format=NV12 ! \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnvstreammux name=mux batch-size=1 width=1280 height=720 ! \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnvinfer config-file-path=config_infer_primary_yolo11n.txt ! nvtracker ! \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnvmultistreamtiler ! nvvideoconvert ! nvdsosd ! nveglglessink\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# nvstreammux ì„¤ì •\u001b[39;00m\n\u001b[1;32m     11\u001b[0m mux \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mget_by_name(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmux\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mError\u001b[0m: gst_parse_error: could not link nvvconv8 to mux, mux can't handle caps video/x-raw(memory:NVMM), format=(string)NV12 (3)"
     ]
    }
   ],
   "source": [
    "# DeepStream íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "pipeline = Gst.parse_launch(\n",
    "    \"nvv4l2camerasrc device=/dev/video0 ! video/x-raw(memory:NVMM), width=1280, height=720, framerate=30/1 ! \"\n",
    "    \"nvvidconv ! video/x-raw(memory:NVMM), format=NV12 ! \"\n",
    "    \"mux.sink_0 \"\n",
    "    \"nvstreammux name=mux batch-size=1 width=1280 height=720 ! \"\n",
    "    \"nvinfer config-file-path=config_infer_primary_yolo11n.txt ! nvtracker ! \"\n",
    "    \"nvmultistreamtiler ! nvvideoconvert ! nvdsosd ! nveglglessink\"\n",
    ")\n",
    "\n",
    "# nvstreammux ì„¤ì •\n",
    "mux = pipeline.get_by_name(\"mux\")\n",
    "if mux:\n",
    "    mux.set_property(\"width\", 1280)\n",
    "    mux.set_property(\"height\", 720)\n",
    "    mux.set_property(\"batch-size\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using winsys: x11 \n",
      "DeepStream íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...\n",
      "ì—ëŸ¬: gst-library-error-quark: Output width not set (5), ë””ë²„ê·¸ ì •ë³´: /dvs/git/dirty/git-master_linux/deepstream/sdk/src/gst-plugins/gst-nvmultistream/gstnvstreammux.cpp(3161): gst_nvstreammux_change_state (): /GstPipeline:pipeline1/GstNvStreamMux:mux\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "def run_pipeline():\n",
    "    try:\n",
    "        pipeline.set_state(Gst.State.PLAYING)\n",
    "        print(\"DeepStream íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...\")\n",
    "\n",
    "        # GStreamer ë²„ìŠ¤ì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹ \n",
    "        bus = pipeline.get_bus()\n",
    "        while True:\n",
    "            msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)\n",
    "            if msg:\n",
    "                t = msg.type\n",
    "                if t == Gst.MessageType.ERROR:\n",
    "                    err, debug = msg.parse_error()\n",
    "                    print(f\"ì—ëŸ¬: {err}, ë””ë²„ê·¸ ì •ë³´: {debug}\")\n",
    "                    break\n",
    "                elif t == Gst.MessageType.EOS:\n",
    "                    print(\"End-Of-Stream ë„ë‹¬\")\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    finally:\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
